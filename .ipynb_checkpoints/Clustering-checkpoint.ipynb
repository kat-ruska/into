{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "Cluster 0:\n",
      " cat\n",
      " climbing\n",
      " ninja\n",
      " photo\n",
      " ve\n",
      " taken\n",
      " restaurant\n",
      " came\n",
      " play\n",
      " little\n",
      "Cluster 1:\n",
      " google\n",
      " translate\n",
      " app\n",
      " feedback\n",
      " impressed\n",
      " map\n",
      " incredible\n",
      " chrome\n",
      " extension\n",
      " promoter\n",
      "\n",
      "\n",
      "Prediction\n",
      "[1]\n",
      "[0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruska/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "documents = [\"This little kitty came to play when I was eating at a restaurant.\",\n",
    "             \"Merley has the best squooshy kitten belly.\",\n",
    "             \"Google Translate app is incredible.\",\n",
    "             \"If you open 100 tab in google you get a smiley face.\",\n",
    "             \"Best cat photo I've ever taken.\",\n",
    "             \"Climbing ninja cat.\",\n",
    "             \"Impressed with google map feedback.\",\n",
    "             \"Key promoter extension for Google Chrome.\"]\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "true_k = 2\n",
    "model = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1)\n",
    "model.fit(X)\n",
    "\n",
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "for i in range(true_k):\n",
    "    print(\"Cluster %d:\" % i),\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind]),\n",
    "    print\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Prediction\")\n",
    "\n",
    "Y = vectorizer.transform([\"chrome browser to open.\"])\n",
    "prediction = model.predict(Y)\n",
    "print(prediction)\n",
    "\n",
    "Y = vectorizer.transform([\"My cat is hungry.\"])\n",
    "prediction = model.predict(Y)\n",
    "print(prediction)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_text = \"\"\"\n",
    "Google and Facebook are strangling the free press to death. Democracy is the loser\n",
    "Your 60-second guide to security stuff Google touted today at Next '18\n",
    "A Guide to Using Android Without Selling Your Soul to Google\n",
    "Review: Lenovo’s Google Smart Display is pretty and intelligent\n",
    "Google Maps user spots mysterious object submerged off the coast of Greece - and no-one knows what it is\n",
    "Android is better than IOS\n",
    "In information retrieval, tf–idf or TFIDF, short for term frequency–inverse document frequency\n",
    "is a numerical statistic that is intended to reflect\n",
    "how important a word is to a document in a collection or corpus.\n",
    "It is often used as a weighting factor in searches of information retrieval\n",
    "text mining, and user modeling. The tf-idf value increases proportionally\n",
    "to the number of times a word appears in the document\n",
    "and is offset by the frequency of the word in the corpus\n",
    "\"\"\".split(\"\\n\")[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Google and Facebook are strangling the free press to death. Democracy is the loser', \"Your 60-second guide to security stuff Google touted today at Next '18\", 'A Guide to Using Android Without Selling Your Soul to Google', 'Review: Lenovo’s Google Smart Display is pretty and intelligent', 'Google Maps user spots mysterious object submerged off the coast of Greece - and no-one knows what it is', 'Android is better than IOS', 'In information retrieval, tf–idf or TFIDF, short for term frequency–inverse document frequency', 'is a numerical statistic that is intended to reflect', 'how important a word is to a document in a collection or corpus.', 'It is often used as a weighting factor in searches of information retrieval', 'text mining, and user modeling. The tf-idf value increases proportionally', 'to the number of times a word appears in the document', 'and is offset by the frequency of the word in the corpus']\n"
     ]
    }
   ],
   "source": [
    "print(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "def preprocessing(line):\n",
    "    line = line.lower()\n",
    "    line = re.sub(r\"[{}]\".format(string.punctuation), \" \", line)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google and facebook are strangling the free press to death\n"
     ]
    }
   ],
   "source": [
    "print(preprocessing('Google and Facebook are strangling the free press to death'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruska/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(preprocessor=preprocessing)\n",
    "tfidf = tfidf_vectorizer.fit_transform(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2',\n",
      "        preprocessor=<function preprocessing at 0x1a2045a488>,\n",
      "        smooth_idf=True, stop_words=None, strip_accents=None,\n",
      "        sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, use_idf=True, vocabulary=None)\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 22)\t0.18968078842212527\n",
      "  (0, 2)\t0.18968078842212527\n",
      "  (0, 17)\t0.30248644340248876\n",
      "  (0, 5)\t0.30248644340248876\n",
      "  (0, 70)\t0.30248644340248876\n",
      "  (0, 79)\t0.37936157684425054\n",
      "  (0, 20)\t0.30248644340248876\n",
      "  (0, 55)\t0.30248644340248876\n",
      "  (0, 81)\t0.17385257624668746\n",
      "  (0, 13)\t0.30248644340248876\n",
      "  (0, 14)\t0.30248644340248876\n",
      "  (0, 35)\t0.14804757753998937\n",
      "  (0, 39)\t0.30248644340248876\n",
      "  (1, 22)\t0.18728256075246552\n",
      "  (1, 81)\t0.17165447246261542\n",
      "  (1, 92)\t0.25755513657107676\n",
      "  (1, 1)\t0.2986619582540487\n",
      "  (1, 62)\t0.2986619582540487\n",
      "  (1, 24)\t0.25755513657107676\n",
      "  (1, 63)\t0.2986619582540487\n",
      "  (1, 71)\t0.2986619582540487\n",
      "  (1, 83)\t0.2986619582540487\n",
      "  (1, 82)\t0.2986619582540487\n",
      "  (1, 7)\t0.2986619582540487\n",
      "  (1, 44)\t0.2986619582540487\n",
      "  :\t:\n",
      "  (10, 74)\t0.3330106455660763\n",
      "  (10, 41)\t0.3330106455660763\n",
      "  (10, 42)\t0.3330106455660763\n",
      "  (10, 87)\t0.3330106455660763\n",
      "  (10, 29)\t0.3330106455660763\n",
      "  (10, 57)\t0.3330106455660763\n",
      "  (11, 79)\t0.47604409702055495\n",
      "  (11, 81)\t0.21815992373953516\n",
      "  (11, 49)\t0.26151395599648214\n",
      "  (11, 28)\t0.23802204851027747\n",
      "  (11, 16)\t0.2902657270749879\n",
      "  (11, 91)\t0.2902657270749879\n",
      "  (11, 46)\t0.37957688548309637\n",
      "  (11, 80)\t0.37957688548309637\n",
      "  (11, 4)\t0.37957688548309637\n",
      "  (12, 2)\t0.2077382977898367\n",
      "  (12, 79)\t0.6232148933695102\n",
      "  (12, 35)\t0.16214162755176964\n",
      "  (12, 49)\t0.2282413096056087\n",
      "  (12, 28)\t0.2077382977898367\n",
      "  (12, 21)\t0.28568632040984115\n",
      "  (12, 91)\t0.2533349680279038\n",
      "  (12, 12)\t0.28568632040984115\n",
      "  (12, 51)\t0.3312829906479083\n",
      "  (12, 9)\t0.3312829906479083\n"
     ]
    }
   ],
   "source": [
    "print(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2).fit(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_for_predicting = [\"tf and idf is awesome!\", \"some androids is there\"]\n",
    "kmeans.predict(tfidf_vectorizer.transform(lines_for_predicting))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruska/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:10: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2500x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentences = ['hi', 'hello', 'hi hello', 'goodbye', 'bye', 'goodbye bye']\n",
    "sentences_split = [s.lower().split(' ') for s in sentences]\n",
    "\n",
    "import gensim\n",
    "model = gensim.models.Word2Vec(sentences_split, min_count=2)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "l = linkage(model.wv.syn0, method='complete', metric='seuclidean')\n",
    "\n",
    "# calculate full dendrogram\n",
    "plt.figure(figsize=(25, 10))\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.ylabel('word')\n",
    "plt.xlabel('distance')\n",
    "\n",
    "dendrogram(\n",
    "    l,\n",
    "    leaf_rotation=90.,  # rotates the x axis labels\n",
    "    leaf_font_size=16.,  # font size for the x axis labels\n",
    "    orientation='left',\n",
    "    leaf_label_func=lambda v: str(model.wv.index2word[v])\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/27/6fdcddfbce1963989eb527f0ba4749829509c0172c275806cffd5a7e1776/gensim-3.8.1-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (24.7MB)\n",
      "\u001b[K    100% |████████████████████████████████| 24.7MB 623kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.18.1 in /Users/ruska/anaconda/lib/python3.6/site-packages (from gensim) (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /Users/ruska/anaconda/lib/python3.6/site-packages (from gensim) (1.17.2)\n",
      "Collecting smart-open>=1.8.1 (from gensim)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/09/735f2786dfac9bbf39d244ce75c0313d27d4962e71e0774750dc809f2395/smart_open-1.9.0.tar.gz (70kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 14.9MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5.0 in /Users/ruska/anaconda/lib/python3.6/site-packages (from gensim) (1.11.0)\n",
      "Requirement already satisfied: boto>=2.32 in /Users/ruska/anaconda/lib/python3.6/site-packages (from smart-open>=1.8.1->gensim) (2.46.1)\n",
      "Requirement already satisfied: requests in /Users/ruska/anaconda/lib/python3.6/site-packages (from smart-open>=1.8.1->gensim) (2.21.0)\n",
      "Collecting boto3 (from smart-open>=1.8.1->gensim)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/a9/1ceaeda8aa5d3effc9098ae301820e27bf54c4000ec6f8ec79f9b265c50e/boto3-1.10.19-py2.py3-none-any.whl (128kB)\n",
      "\u001b[K    100% |████████████████████████████████| 133kB 18.2MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: idna<2.9,>=2.5 in /Users/ruska/anaconda/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (2.5)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /Users/ruska/anaconda/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (1.24.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ruska/anaconda/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (2019.3.9)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/ruska/anaconda/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.3)\n",
      "Collecting jmespath<1.0.0,>=0.7.1 (from boto3->smart-open>=1.8.1->gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/83/94/7179c3832a6d45b266ddb2aac329e101367fbdb11f425f13771d27f225bb/jmespath-0.9.4-py2.py3-none-any.whl\n",
      "Collecting s3transfer<0.3.0,>=0.2.0 (from boto3->smart-open>=1.8.1->gensim)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/8a/1fc3dba0c4923c2a76e1ff0d52b305c44606da63f718d14d3231e21c51b0/s3transfer-0.2.1-py2.py3-none-any.whl (70kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 9.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting botocore<1.14.0,>=1.13.19 (from boto3->smart-open>=1.8.1->gensim)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/e5/0f29669244ffacc15c4cec9e10d75c26e7d300e1786e79514e62373e648c/botocore-1.13.19-py2.py3-none-any.whl (5.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 5.4MB 2.0MB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: docutils<0.16,>=0.10 in /Users/ruska/anaconda/lib/python3.6/site-packages (from botocore<1.14.0,>=1.13.19->boto3->smart-open>=1.8.1->gensim) (0.13.1)\n",
      "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /Users/ruska/anaconda/lib/python3.6/site-packages (from botocore<1.14.0,>=1.13.19->boto3->smart-open>=1.8.1->gensim) (2.7.3)\n",
      "Building wheels for collected packages: smart-open\n",
      "  Running setup.py bdist_wheel for smart-open ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/ruska/Library/Caches/pip/wheels/ab/10/93/5cff86f5b721d77edaecc29959b1c60d894be1f66d91407d28\n",
      "Successfully built smart-open\n",
      "Installing collected packages: jmespath, botocore, s3transfer, boto3, smart-open, gensim\n",
      "Successfully installed boto3-1.10.19 botocore-1.13.19 gensim-3.8.1 jmespath-0.9.4 s3transfer-0.2.1 smart-open-1.9.0\n",
      "\u001b[33mYou are using pip version 18.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
