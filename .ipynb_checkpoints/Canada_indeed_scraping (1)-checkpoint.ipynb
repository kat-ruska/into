{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Canada Indeed scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\yaroslav\\anaconda3\\lib\\site-packages (4.7.1)\n",
      "Requirement already satisfied: soupsieve>=1.2 in c:\\users\\yaroslav\\anaconda3\\lib\\site-packages (from beautifulsoup4) (1.8)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from bs4 import beautifulsoup4\n",
    "except:\n",
    "    !pip install beautifulsoup4\n",
    "\n",
    "import matplotlib as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bs4\n",
    "import re\n",
    "from urllib.request import urlopen as url_request\n",
    "from bs4 import BeautifulSoup as soup\n",
    "\n",
    "#https://www.indeed.ca/jobs?q=data+scientist&l=Toronto&start=\n",
    "#https://www.indeed.ca/jobs?q=data+scientist&start=60  nationwide\n",
    "#global declarations\n",
    "#Canadian Indeed site operates 20 postings per page\n",
    "postings_per_page = 20\n",
    "\n",
    "def get_soup(link):\n",
    "    url_client = url_request(link)\n",
    "    page_body = url_client.read()\n",
    "    url_client.close()\n",
    "    return soup(page_body, 'html.parser')\n",
    "\n",
    "def get_salary_estimators(page_soup):\n",
    "    salary_estimators_soup = page_soup.select(\"div#SALARY_rbo ul.rbList li\")\n",
    "\n",
    "    salary_estimators =[]\n",
    "\n",
    "    for salary_estimator_soup in salary_estimators_soup:\n",
    "\n",
    "        link = salary_estimator_soup.find(\"a\")[\"href\"]\n",
    "\n",
    "        salary = int(salary_estimator_soup\\\n",
    "            .find(\"span\",{\"class\": \"rbLabel\"}).string\\\n",
    "            .replace(\"$\",\"\")\\\n",
    "            .replace(\",\",\"\"))\n",
    "        count = int(salary_estimator_soup\\\n",
    "            .find(\"span\",{\"class\": \"rbCount\"}).string.\\\n",
    "            replace(\"(\",\"\")\\\n",
    "            .replace(\")\",\"\"))\n",
    "\n",
    "        salary_estimators.append((link,salary,count))\n",
    "\n",
    "    salary_estimators.reverse()\n",
    "    return salary_estimators\n",
    "\n",
    "def get_positions(site, location, jobtitle, skills_search_words):\n",
    "\n",
    "    # Empty list for job_title, company_name, location, job_description, job skills\n",
    "    titles = []\n",
    "    company_names = []\n",
    "    location_names = []\n",
    "    job_descriptions = []\n",
    "    job_ids = []\n",
    "    salaries = []\n",
    "    \n",
    "    # Empty Skills data dict construction\n",
    "    skills_data = {}\n",
    "    for skill in skills_search_words:\n",
    "        skills_data[skill]=[] \n",
    "\n",
    "    # Compiling start query string\n",
    "    start_url = site + '/jobs?q=' + jobtitle.replace(' ', '+') + '&l=' + location.replace(' ', '+')\n",
    "    \n",
    "    # getting first page\n",
    "    page_soup = get_soup(start_url)\n",
    "    \n",
    "    # creating dict with compensations filters\n",
    "    salary_estimators = get_salary_estimators(page_soup)\n",
    "    \n",
    "    #print(salary_estimators)\n",
    "     \n",
    "    # test estimator    \n",
    "    # salary_estimators = [('/q-data-scientist-$135,000-l-New-York-jobs.html', 135000, 10)]\n",
    "\n",
    "    # walk throught each salary estimator\n",
    "    for salary_estimator in salary_estimators:\n",
    "        (initial_url, salary, count) = salary_estimator\n",
    "\n",
    "        print(f'Parsing positions with {salary}+ compensation({count})')\n",
    "        \n",
    "        # at first we have something like   https://www.indeed.com/q-data-scientist-$135,000-l-New-York-jobs.html\n",
    "        # and we should retrive url from pagination\n",
    "        parse_url = initial_url\n",
    "\n",
    "        # Loop over vacancies (20 at each page - for Canadian site)\n",
    "        #if count > 25: count = 25  #testing with small numbers\n",
    "            \n",
    "        for i in range(0, count, postings_per_page):\n",
    "            # html parsing Indeed job portal page\n",
    "            print(f'    Processed - {i}')\n",
    "            print(f'      initial_url {initial_url}')\n",
    "            print(f'      parse_url {parse_url}')\n",
    "            print(f'      count {count}')\n",
    "            # first entrance\n",
    "            if (initial_url==parse_url):                   \n",
    "                page_soup = get_soup(site+initial_url)\n",
    "                # if there are few vacancies then pagination is absent\n",
    "                if (count > postings_per_page):\n",
    "                    # calculation iterable url\n",
    "                    parse_url = page_soup.find(\"div\", {\"class\": \"pagination\"}).find(\"a\")[\"href\"]\n",
    "                    parse_url = re.search('(.*)start=', parse_url).group(0)\n",
    "            else:\n",
    "                page_soup = get_soup(site + parse_url+str(i))\n",
    "\n",
    "            # getting jobs from list\n",
    "            jobs = page_soup.findAll(\"div\", class_=\"row\")\n",
    "            for job in jobs:\n",
    "\n",
    "                job_url = job.a[\"href\"]\n",
    "                # parsing position ID\n",
    "                try:\n",
    "                    job_id = re.search('clk\\?jk=(.*)&fccid', job_url).group(1)\n",
    "\n",
    "                    #skip already parsed jobs\n",
    "                    if job_id in job_ids:\n",
    "                        continue\n",
    "                    job_ids.append(job_id)\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "                salaries.append(salary)\n",
    "\n",
    "                # extract job_title\n",
    "                try:\n",
    "                    titles.append(job.a[\"title\"])\n",
    "                except:\n",
    "                    titles.append(\"NA\")\n",
    "\n",
    "                # extract company_name\n",
    "                try:\n",
    "                    company_names.append(job.find(\"span\", class_=\"company\").text.strip())\n",
    "                except:\n",
    "                    company_names.append(\"NA\")\n",
    "\n",
    "                # extract location\n",
    "                try:\n",
    "                    location_names.append(job.find(class_=\"location\").text)\n",
    "                except:\n",
    "                    location_names.append(\"NA\")\n",
    "\n",
    "                # extract description from position view\n",
    "                job_soup = get_soup(site + job_url)\n",
    "\n",
    "                job_description = job_soup.findAll(\"div\", class_=\"jobsearch-JobComponent-description\")\n",
    "                cleantext = soup(str(job_description), 'lxml').text\n",
    "                try:\n",
    "                    job_descriptions.append(cleantext)\n",
    "                except:\n",
    "                    job_descriptions.append(\"NA\")\n",
    "                    \n",
    "                # Skills\n",
    "                for (skill, search_words) in skills_search_words.items():\n",
    "    \n",
    "                    # rearching\n",
    "                    skill_data = skills_data.get(skill);\n",
    "                \n",
    "                    # loop search words\n",
    "                    is_in_text = False\n",
    "            \n",
    "                    for search_word in search_words:\n",
    "                        if skill.lower() in cleantext.lower():\n",
    "                            is_in_text = True\n",
    "                            break\n",
    "                            \n",
    "                    # updating\n",
    "                    skill_data.append('1' if is_in_text else '0')\n",
    "                    skills_data[skill]=skill_data \n",
    "    \n",
    "    \n",
    "    data = {'Job_ID': job_ids, 'Salary': salaries, 'Job_Title': titles, 'Company_Name': company_names, 'Location': location_names,\n",
    "         'Job_Description': job_descriptions}\n",
    "    \n",
    "    for (skill, skill_data) in skills_data.items():\n",
    "        data[skill] = skill_data\n",
    "    \n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "site = 'https://www.indeed.ca'\n",
    "jobtitle = 'data scientist'\n",
    "location = ''\n",
    "#locations = ['New York', 'Seattle', 'San Francisco', 'Boston']\n",
    "skills_search_words = {\n",
    "    'Python' : ['python','numpy', 'pandas', 'scikit-learn', 'matplotlib'],\n",
    "    'R' : [',R ',' R '],\n",
    "    'Math' : ['math'],    \n",
    "    'Artificial Intelligence': ['artificial intelligence','AI'],\n",
    "    'Deep learning': ['deep learning'],\n",
    "    'Business Skils': ['collaborating','stakeholder','management'],\n",
    "    'Stats': ['stats, statistics'],\n",
    "    'Machine Learning': ['machine learning'],\n",
    "    'Excel': ['excel'],\n",
    "    'Matlab': ['matlab'],\n",
    "    'SAS': ['sas'],\n",
    "    'SQL': ['sql'],\n",
    "    'SPSS': ['spss'],\n",
    "    'Big Data': ['hadoop','spark'],\n",
    "    'Econometrics': ['econometrics','economet'],\n",
    "    'Leadership': ['decisiveness', 'dependability', 'conflict-resolution', 'constructive criticism', 'delegating tasks', 'empathy', 'empowerment', 'integrity', 'mentoring', 'motivating', 'patience', 'relationship management', 'task delegation', 'team building', 'teamwork'],\n",
    "    'Planning and strategy': ['adaptability', 'brainstorming', 'business development', 'conflict resolution', 'critical thinking', 'decision-making', 'flexibility', 'logical thinking', 'problem-solving', 'problem solving', 'strategic thinking', 'business sense', 'acumen', 'curiosity'],\n",
    "    'Communication': ['active listening', 'building relationships', 'collaboration', 'interpersonal communication', 'interviewing', 'negotiation', 'persuasion', 'public speaking', 'verbal communication', 'written communication', 'communication'],\n",
    "    'Organizational': ['deadline management', 'event coordination', 'filing', 'goal setting', 'office management', 'project management', 'record keeping', 'scheduling', 'time management', 'risk management', 'prioritisation']\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing positions with 144800+ compensation(12)\n",
      "    Processed - 0\n",
      "      initial_url /data-scientist-$144,800-jobs\n",
      "      parse_url /data-scientist-$144,800-jobs\n",
      "      count 12\n",
      "Parsing positions with 120000+ compensation(46)\n",
      "    Processed - 0\n",
      "      initial_url /data-scientist-$120,000-jobs\n",
      "      parse_url /data-scientist-$120,000-jobs\n",
      "      count 46\n",
      "    Processed - 20\n",
      "      initial_url /data-scientist-$120,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%24120%2C000&start=\n",
      "      count 46\n",
      "    Processed - 40\n",
      "      initial_url /data-scientist-$120,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%24120%2C000&start=\n",
      "      count 46\n",
      "Parsing positions with 100000+ compensation(231)\n",
      "    Processed - 0\n",
      "      initial_url /data-scientist-$100,000-jobs\n",
      "      parse_url /data-scientist-$100,000-jobs\n",
      "      count 231\n",
      "    Processed - 20\n",
      "      initial_url /data-scientist-$100,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%24100%2C000&start=\n",
      "      count 231\n",
      "    Processed - 40\n",
      "      initial_url /data-scientist-$100,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%24100%2C000&start=\n",
      "      count 231\n",
      "    Processed - 60\n",
      "      initial_url /data-scientist-$100,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%24100%2C000&start=\n",
      "      count 231\n",
      "    Processed - 80\n",
      "      initial_url /data-scientist-$100,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%24100%2C000&start=\n",
      "      count 231\n",
      "    Processed - 100\n",
      "      initial_url /data-scientist-$100,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%24100%2C000&start=\n",
      "      count 231\n",
      "    Processed - 120\n",
      "      initial_url /data-scientist-$100,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%24100%2C000&start=\n",
      "      count 231\n",
      "    Processed - 140\n",
      "      initial_url /data-scientist-$100,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%24100%2C000&start=\n",
      "      count 231\n",
      "    Processed - 160\n",
      "      initial_url /data-scientist-$100,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%24100%2C000&start=\n",
      "      count 231\n",
      "    Processed - 180\n",
      "      initial_url /data-scientist-$100,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%24100%2C000&start=\n",
      "      count 231\n",
      "    Processed - 200\n",
      "      initial_url /data-scientist-$100,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%24100%2C000&start=\n",
      "      count 231\n",
      "    Processed - 220\n",
      "      initial_url /data-scientist-$100,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%24100%2C000&start=\n",
      "      count 231\n",
      "Parsing positions with 80000+ compensation(645)\n",
      "    Processed - 0\n",
      "      initial_url /data-scientist-$80,000-jobs\n",
      "      parse_url /data-scientist-$80,000-jobs\n",
      "      count 645\n",
      "    Processed - 20\n",
      "      initial_url /data-scientist-$80,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2480%2C000&start=\n",
      "      count 645\n",
      "    Processed - 40\n",
      "      initial_url /data-scientist-$80,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2480%2C000&start=\n",
      "      count 645\n",
      "    Processed - 60\n",
      "      initial_url /data-scientist-$80,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2480%2C000&start=\n",
      "      count 645\n",
      "    Processed - 80\n",
      "      initial_url /data-scientist-$80,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2480%2C000&start=\n",
      "      count 645\n",
      "    Processed - 100\n",
      "      initial_url /data-scientist-$80,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2480%2C000&start=\n",
      "      count 645\n",
      "    Processed - 120\n",
      "      initial_url /data-scientist-$80,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2480%2C000&start=\n",
      "      count 645\n",
      "    Processed - 140\n",
      "      initial_url /data-scientist-$80,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2480%2C000&start=\n",
      "      count 645\n",
      "    Processed - 160\n",
      "      initial_url /data-scientist-$80,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2480%2C000&start=\n",
      "      count 645\n",
      "    Processed - 180\n",
      "      initial_url /data-scientist-$80,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2480%2C000&start=\n",
      "      count 645\n",
      "    Processed - 200\n",
      "      initial_url /data-scientist-$80,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2480%2C000&start=\n",
      "      count 645\n",
      "    Processed - 220\n",
      "      initial_url /data-scientist-$80,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2480%2C000&start=\n",
      "      count 645\n",
      "    Processed - 240\n",
      "      initial_url /data-scientist-$80,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2480%2C000&start=\n",
      "      count 645\n",
      "    Processed - 260\n",
      "      initial_url /data-scientist-$80,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2480%2C000&start=\n",
      "      count 645\n",
      "    Processed - 280\n",
      "      initial_url /data-scientist-$80,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2480%2C000&start=\n",
      "      count 645\n",
      "    Processed - 300\n",
      "      initial_url /data-scientist-$80,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2480%2C000&start=\n",
      "      count 645\n",
      "    Processed - 320\n",
      "      initial_url /data-scientist-$80,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2480%2C000&start=\n",
      "      count 645\n",
      "    Processed - 340\n",
      "      initial_url /data-scientist-$80,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2480%2C000&start=\n",
      "      count 645\n",
      "    Processed - 360\n",
      "      initial_url /data-scientist-$80,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2480%2C000&start=\n",
      "      count 645\n",
      "    Processed - 380\n",
      "      initial_url /data-scientist-$80,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2480%2C000&start=\n",
      "      count 645\n",
      "    Processed - 400\n",
      "      initial_url /data-scientist-$80,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2480%2C000&start=\n",
      "      count 645\n",
      "    Processed - 420\n",
      "      initial_url /data-scientist-$80,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2480%2C000&start=\n",
      "      count 645\n",
      "    Processed - 440\n",
      "      initial_url /data-scientist-$80,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2480%2C000&start=\n",
      "      count 645\n",
      "    Processed - 460\n",
      "      initial_url /data-scientist-$80,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2480%2C000&start=\n",
      "      count 645\n",
      "    Processed - 480\n",
      "      initial_url /data-scientist-$80,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2480%2C000&start=\n",
      "      count 645\n",
      "    Processed - 500\n",
      "      initial_url /data-scientist-$80,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2480%2C000&start=\n",
      "      count 645\n",
      "    Processed - 520\n",
      "      initial_url /data-scientist-$80,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2480%2C000&start=\n",
      "      count 645\n",
      "    Processed - 540\n",
      "      initial_url /data-scientist-$80,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2480%2C000&start=\n",
      "      count 645\n",
      "    Processed - 560\n",
      "      initial_url /data-scientist-$80,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2480%2C000&start=\n",
      "      count 645\n",
      "    Processed - 580\n",
      "      initial_url /data-scientist-$80,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2480%2C000&start=\n",
      "      count 645\n",
      "    Processed - 600\n",
      "      initial_url /data-scientist-$80,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2480%2C000&start=\n",
      "      count 645\n",
      "    Processed - 620\n",
      "      initial_url /data-scientist-$80,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2480%2C000&start=\n",
      "      count 645\n",
      "    Processed - 640\n",
      "      initial_url /data-scientist-$80,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2480%2C000&start=\n",
      "      count 645\n",
      "Parsing positions with 60000+ compensation(1034)\n",
      "    Processed - 0\n",
      "      initial_url /data-scientist-$60,000-jobs\n",
      "      parse_url /data-scientist-$60,000-jobs\n",
      "      count 1034\n",
      "    Processed - 20\n",
      "      initial_url /data-scientist-$60,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2460%2C000&start=\n",
      "      count 1034\n",
      "    Processed - 40\n",
      "      initial_url /data-scientist-$60,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2460%2C000&start=\n",
      "      count 1034\n",
      "    Processed - 60\n",
      "      initial_url /data-scientist-$60,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2460%2C000&start=\n",
      "      count 1034\n",
      "    Processed - 80\n",
      "      initial_url /data-scientist-$60,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2460%2C000&start=\n",
      "      count 1034\n",
      "    Processed - 100\n",
      "      initial_url /data-scientist-$60,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2460%2C000&start=\n",
      "      count 1034\n",
      "    Processed - 120\n",
      "      initial_url /data-scientist-$60,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2460%2C000&start=\n",
      "      count 1034\n",
      "    Processed - 140\n",
      "      initial_url /data-scientist-$60,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2460%2C000&start=\n",
      "      count 1034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Processed - 160\n",
      "      initial_url /data-scientist-$60,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2460%2C000&start=\n",
      "      count 1034\n",
      "    Processed - 180\n",
      "      initial_url /data-scientist-$60,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2460%2C000&start=\n",
      "      count 1034\n",
      "    Processed - 200\n",
      "      initial_url /data-scientist-$60,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2460%2C000&start=\n",
      "      count 1034\n",
      "    Processed - 220\n",
      "      initial_url /data-scientist-$60,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2460%2C000&start=\n",
      "      count 1034\n",
      "    Processed - 240\n",
      "      initial_url /data-scientist-$60,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2460%2C000&start=\n",
      "      count 1034\n",
      "    Processed - 260\n",
      "      initial_url /data-scientist-$60,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2460%2C000&start=\n",
      "      count 1034\n",
      "    Processed - 280\n",
      "      initial_url /data-scientist-$60,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2460%2C000&start=\n",
      "      count 1034\n",
      "    Processed - 300\n",
      "      initial_url /data-scientist-$60,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2460%2C000&start=\n",
      "      count 1034\n",
      "    Processed - 320\n",
      "      initial_url /data-scientist-$60,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2460%2C000&start=\n",
      "      count 1034\n",
      "    Processed - 340\n",
      "      initial_url /data-scientist-$60,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2460%2C000&start=\n",
      "      count 1034\n",
      "    Processed - 360\n",
      "      initial_url /data-scientist-$60,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2460%2C000&start=\n",
      "      count 1034\n",
      "    Processed - 380\n",
      "      initial_url /data-scientist-$60,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2460%2C000&start=\n",
      "      count 1034\n",
      "    Processed - 400\n",
      "      initial_url /data-scientist-$60,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2460%2C000&start=\n",
      "      count 1034\n",
      "    Processed - 420\n",
      "      initial_url /data-scientist-$60,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2460%2C000&start=\n",
      "      count 1034\n",
      "    Processed - 440\n",
      "      initial_url /data-scientist-$60,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2460%2C000&start=\n",
      "      count 1034\n",
      "    Processed - 460\n",
      "      initial_url /data-scientist-$60,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2460%2C000&start=\n",
      "      count 1034\n",
      "    Processed - 480\n",
      "      initial_url /data-scientist-$60,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2460%2C000&start=\n",
      "      count 1034\n",
      "    Processed - 500\n",
      "      initial_url /data-scientist-$60,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2460%2C000&start=\n",
      "      count 1034\n",
      "    Processed - 520\n",
      "      initial_url /data-scientist-$60,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2460%2C000&start=\n",
      "      count 1034\n",
      "    Processed - 540\n",
      "      initial_url /data-scientist-$60,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2460%2C000&start=\n",
      "      count 1034\n",
      "    Processed - 560\n",
      "      initial_url /data-scientist-$60,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2460%2C000&start=\n",
      "      count 1034\n",
      "    Processed - 580\n",
      "      initial_url /data-scientist-$60,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2460%2C000&start=\n",
      "      count 1034\n",
      "    Processed - 600\n",
      "      initial_url /data-scientist-$60,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2460%2C000&start=\n",
      "      count 1034\n",
      "    Processed - 620\n",
      "      initial_url /data-scientist-$60,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2460%2C000&start=\n",
      "      count 1034\n",
      "    Processed - 640\n",
      "      initial_url /data-scientist-$60,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2460%2C000&start=\n",
      "      count 1034\n",
      "    Processed - 660\n",
      "      initial_url /data-scientist-$60,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2460%2C000&start=\n",
      "      count 1034\n",
      "    Processed - 680\n",
      "      initial_url /data-scientist-$60,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2460%2C000&start=\n",
      "      count 1034\n",
      "    Processed - 700\n",
      "      initial_url /data-scientist-$60,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2460%2C000&start=\n",
      "      count 1034\n",
      "    Processed - 720\n",
      "      initial_url /data-scientist-$60,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2460%2C000&start=\n",
      "      count 1034\n",
      "    Processed - 740\n",
      "      initial_url /data-scientist-$60,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2460%2C000&start=\n",
      "      count 1034\n",
      "    Processed - 760\n",
      "      initial_url /data-scientist-$60,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2460%2C000&start=\n",
      "      count 1034\n",
      "    Processed - 780\n",
      "      initial_url /data-scientist-$60,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2460%2C000&start=\n",
      "      count 1034\n",
      "    Processed - 800\n",
      "      initial_url /data-scientist-$60,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2460%2C000&start=\n",
      "      count 1034\n",
      "    Processed - 820\n",
      "      initial_url /data-scientist-$60,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2460%2C000&start=\n",
      "      count 1034\n",
      "    Processed - 840\n",
      "      initial_url /data-scientist-$60,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2460%2C000&start=\n",
      "      count 1034\n",
      "    Processed - 860\n",
      "      initial_url /data-scientist-$60,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2460%2C000&start=\n",
      "      count 1034\n",
      "    Processed - 880\n",
      "      initial_url /data-scientist-$60,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2460%2C000&start=\n",
      "      count 1034\n",
      "    Processed - 900\n",
      "      initial_url /data-scientist-$60,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2460%2C000&start=\n",
      "      count 1034\n",
      "    Processed - 920\n",
      "      initial_url /data-scientist-$60,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2460%2C000&start=\n",
      "      count 1034\n",
      "    Processed - 940\n",
      "      initial_url /data-scientist-$60,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2460%2C000&start=\n",
      "      count 1034\n",
      "    Processed - 960\n",
      "      initial_url /data-scientist-$60,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2460%2C000&start=\n",
      "      count 1034\n",
      "    Processed - 980\n",
      "      initial_url /data-scientist-$60,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2460%2C000&start=\n",
      "      count 1034\n",
      "    Processed - 1000\n",
      "      initial_url /data-scientist-$60,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2460%2C000&start=\n",
      "      count 1034\n",
      "    Processed - 1020\n",
      "      initial_url /data-scientist-$60,000-jobs\n",
      "      parse_url /jobs?q=data+scientist+%2460%2C000&start=\n",
      "      count 1034\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_ID</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job_Description</th>\n",
       "      <th>Python</th>\n",
       "      <th>R</th>\n",
       "      <th>Math</th>\n",
       "      <th>Artificial Intelligence</th>\n",
       "      <th>...</th>\n",
       "      <th>Matlab</th>\n",
       "      <th>SAS</th>\n",
       "      <th>SQL</th>\n",
       "      <th>SPSS</th>\n",
       "      <th>Big Data</th>\n",
       "      <th>Econometrics</th>\n",
       "      <th>Leadership</th>\n",
       "      <th>Planning and strategy</th>\n",
       "      <th>Communication</th>\n",
       "      <th>Organizational</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69c7eca5aac92b3d</td>\n",
       "      <td>144800</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>University of British Columbia</td>\n",
       "      <td>Vancouver, BC</td>\n",
       "      <td>[Vancouver, BCPart-time$12,368 a monthJob Post...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65d076b8bd977448</td>\n",
       "      <td>144800</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>UBC Sauder</td>\n",
       "      <td>Vancouver, BC</td>\n",
       "      <td>[Vancouver, BCPart-time$12,368 a monthJob Post...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84ee47be32aed34f</td>\n",
       "      <td>144800</td>\n",
       "      <td>Applied Scientist II</td>\n",
       "      <td>AMZN CAN Fulfillment Svcs, ULC</td>\n",
       "      <td>Vancouver, BC</td>\n",
       "      <td>[Vancouver, BC$127,400 - $212,700 a yearA Mast...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84aa786591b21f98</td>\n",
       "      <td>144800</td>\n",
       "      <td>Data Engineer III</td>\n",
       "      <td>Amazon Web Services Canada, In</td>\n",
       "      <td>Vancouver, BC</td>\n",
       "      <td>[Vancouver, BC$110,700 - $184,900 a yearBachel...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40db3cd9efa844c7</td>\n",
       "      <td>144800</td>\n",
       "      <td>Director of Data Science</td>\n",
       "      <td>AltaML Inc./Janalta Interactive Inc.</td>\n",
       "      <td>Edmonton, AB</td>\n",
       "      <td>[Edmonton, ABAbout company\\n\\nAltaML is a fast...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Job_ID  Salary                 Job_Title  \\\n",
       "0  69c7eca5aac92b3d  144800            Data Scientist   \n",
       "1  65d076b8bd977448  144800            Data Scientist   \n",
       "2  84ee47be32aed34f  144800      Applied Scientist II   \n",
       "3  84aa786591b21f98  144800         Data Engineer III   \n",
       "4  40db3cd9efa844c7  144800  Director of Data Science   \n",
       "\n",
       "                           Company_Name       Location  \\\n",
       "0        University of British Columbia  Vancouver, BC   \n",
       "1                            UBC Sauder  Vancouver, BC   \n",
       "2        AMZN CAN Fulfillment Svcs, ULC  Vancouver, BC   \n",
       "3        Amazon Web Services Canada, In  Vancouver, BC   \n",
       "4  AltaML Inc./Janalta Interactive Inc.   Edmonton, AB   \n",
       "\n",
       "                                     Job_Description Python  R Math  \\\n",
       "0  [Vancouver, BCPart-time$12,368 a monthJob Post...      1  1    0   \n",
       "1  [Vancouver, BCPart-time$12,368 a monthJob Post...      1  1    0   \n",
       "2  [Vancouver, BC$127,400 - $212,700 a yearA Mast...      0  1    0   \n",
       "3  [Vancouver, BC$110,700 - $184,900 a yearBachel...      1  1    0   \n",
       "4  [Edmonton, ABAbout company\\n\\nAltaML is a fast...      0  1    0   \n",
       "\n",
       "  Artificial Intelligence  ... Matlab SAS SQL SPSS Big Data Econometrics  \\\n",
       "0                       0  ...      0   0   0    1        0            0   \n",
       "1                       0  ...      0   0   0    1        0            0   \n",
       "2                       0  ...      0   0   0    0        1            0   \n",
       "3                       0  ...      0   0   1    0        1            0   \n",
       "4                       0  ...      0   0   0    0        0            0   \n",
       "\n",
       "  Leadership Planning and strategy Communication Organizational  \n",
       "0          0                     0             1              1  \n",
       "1          0                     0             1              1  \n",
       "2          0                     0             0              0  \n",
       "3          0                     0             0              0  \n",
       "4          0                     0             0              0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_positions(site, location, jobtitle, skills_search_words)\n",
    "df.to_csv('Canada_Indeed_job_vacancies.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
